{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PositionalEmbedding3D import PositionalEmbedding3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0, 0) (5, 0, 1) (5, 0, 2) (5, 0, 3) (5, 0, 4) (5, 1, 0) (5, 1, 1)\n",
      " (5, 1, 2) (5, 1, 3) (5, 1, 4) (5, 2, 0) (5, 2, 1) (5, 2, 2) (5, 2, 3)\n",
      " (5, 2, 4) (5, 3, 0) (5, 3, 1) (5, 3, 2) (5, 3, 3) (5, 3, 4) (5, 4, 0)\n",
      " (5, 4, 1) (5, 4, 2) (5, 4, 3) (5, 4, 4)]\n",
      "<class 'list'> <class 'list'> <class 'list'> \n",
      "tensor([6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5])\n",
      "tensor([5, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4,\n",
      "        4, 4])\n",
      "tensor([5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2,\n",
      "        3, 4]) \n",
      "torch.Size([125, 256])\n",
      "torch.Size([125, 256])\n",
      "torch.Size([125, 256])\n",
      "\n",
      "torch.Size([125, 768])\n",
      "torch.Size([26, 768])\n",
      "torch.Size([1, 26, 255])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3879)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MinecraftSequencePredict(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, src_shape: tuple, tgt_shape: tuple, tgt_offset: tuple):\n",
    "        super(MinecraftSequencePredict, self).__init__()\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding3D(d_model, src_shape, tgt_shape, tgt_offset)\n",
    "        # Define the transformer model\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "        \n",
    "        src = self.pos_embedding(src, True)\n",
    "        tgt = self.pos_embedding(tgt, False)\n",
    "        output = self.transformer(src, tgt)\n",
    "\n",
    "        # You may want to reshape or slice the output based on your specific task\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "vocab_size = 255  # Adjust based on your vocabulary size\n",
    "d_model = 768\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "\n",
    "src_shape  = (5,5,5)\n",
    "tgt_shape  = (1,5,5)\n",
    "tgt_offset = (5,0,0)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility (optional)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a 5x5x5 tensor with random integers from 0 to 255\n",
    "src = torch.randint(0, vocab_size - 1, size=src_shape, dtype=torch.int).ravel().unsqueeze(0)\n",
    "tgt = torch.cat([torch.tensor([vocab_size-1]),torch.randint(0, vocab_size - 1, size=tgt_shape, dtype=torch.int).ravel()]).unsqueeze(0)\n",
    "tgt_sos = torch.tensor([vocab_size-1]).unsqueeze(0)\n",
    "\n",
    "\n",
    "model = MinecraftSequencePredict(vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, src_shape, tgt_shape, tgt_offset)\n",
    "\n",
    "output = model(src, tgt)\n",
    "print(output.shape)\n",
    "torch.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[170,  67, 148, 136, 200, 159, 242, 104,  24, 201,  84, 236,  94, 110,\n",
      "         185, 182,  31, 175, 217, 132, 223, 102,   9,  79, 247,  61,   1,  97,\n",
      "         143, 231, 142, 112, 109,  23, 137, 120, 155, 250, 188, 182, 122,  64,\n",
      "          93, 183,  89, 201, 177,  24, 111,  55, 156,  11, 232,  51, 170, 189,\n",
      "         157,  62, 202, 130,  86, 232,   2,  16,  58, 107,  37,   6,  37, 181,\n",
      "         131,  15, 190, 141,  22, 131,  73, 203,  92, 157, 132, 179, 220, 117,\n",
      "         138,  78, 183,   2, 133,  81,  73, 209,  77, 205, 157,  37,  15, 135,\n",
      "          59, 120, 206, 205,  11, 131,  65, 187,  17,  73,  17, 242, 131, 106,\n",
      "         253, 195, 246,  77, 172, 119, 155,  46, 167, 240, 159, 242, 202]],\n",
      "       dtype=torch.int32)\n",
      "tensor([[254,  77,  41, 252, 145, 107, 213, 136, 208, 138, 136, 154, 176, 248,\n",
      "          12,  22,   3, 242,  17, 129,  85,  62,  78, 212,  10, 175]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "vocab_size = 255  # Adjust based on your vocabulary size\n",
    "d_model = 768\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "\n",
    "src_shape  = (5,5,5)\n",
    "tgt_shape  = (1,5,5)\n",
    "tgt_offset = (5,0,0)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility (optional)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a 5x5x5 tensor with random integers from 0 to 255\n",
    "src = torch.randint(0, vocab_size - 1, size=src_shape, dtype=torch.int).ravel().unsqueeze(0)\n",
    "tgt = torch.cat([torch.tensor([vocab_size-1]),torch.randint(0, vocab_size - 1, size=tgt_shape, dtype=torch.int).ravel()]).unsqueeze(0)\n",
    "\n",
    "print(src)\n",
    "print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0) (0, 0, 1) (0, 0, 2) (0, 0, 3) (0, 1, 0) (0, 1, 1) (0, 1, 2)\n",
      " (0, 1, 3) (0, 2, 0) (0, 2, 1) (0, 2, 2) (0, 2, 3) (0, 3, 0) (0, 3, 1)\n",
      " (0, 3, 2) (0, 3, 3) (1, 0, 0) (1, 0, 1) (1, 0, 2) (1, 0, 3) (1, 1, 0)\n",
      " (1, 1, 1) (1, 1, 2) (1, 1, 3) (1, 2, 0) (1, 2, 1) (1, 2, 2) (1, 2, 3)\n",
      " (1, 3, 0) (1, 3, 1) (1, 3, 2) (1, 3, 3) (2, 0, 0) (2, 0, 1) (2, 0, 2)\n",
      " (2, 0, 3) (2, 1, 0) (2, 1, 1) (2, 1, 2) (2, 1, 3) (2, 2, 0) (2, 2, 1)\n",
      " (2, 2, 2) (2, 2, 3) (2, 3, 0) (2, 3, 1) (2, 3, 2) (2, 3, 3) (3, 0, 0)\n",
      " (3, 0, 1) (3, 0, 2) (3, 0, 3) (3, 1, 0) (3, 1, 1) (3, 1, 2) (3, 1, 3)\n",
      " (3, 2, 0) (3, 2, 1) (3, 2, 2) (3, 2, 3) (3, 3, 0) (3, 3, 1) (3, 3, 2)\n",
      " (3, 3, 3)]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# position = torch.arange(0, x.size(1)).unsqueeze(0)\n",
    "shape = (4,4,4)\n",
    "\n",
    "array_3d = np.empty(shape, dtype=object)\n",
    "\n",
    "# Fill in the array with tuples of indices\n",
    "for i in range(shape[0]):\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            array_3d[i, j, k] = (i, j, k)\n",
    "array_3d = array_3d.ravel()\n",
    "print(array_3d)\n",
    "arr = [i[0] for _, i in np.ndenumerate(array_3d)]\n",
    "arr.insert(0, 12)\n",
    "print(type(arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
